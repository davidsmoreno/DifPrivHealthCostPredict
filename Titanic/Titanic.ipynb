{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data=pd.read_csv('Titanic-Dataset.csv')\n",
    "titanic_data.head()\n",
    "\n",
    "titanic_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 60 members, which is less than n_splits=100.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracies: [1.  1.  0.5 1.  0.5 1.  1.  1.  0.  1.  0.5 0.5 1.  1.  0.5 1.  1.  1.\n",
      " 1.  1.  1.  1.  1.  1.  0.5 1.  1.  1.  0.5 1.  1.  1.  0.5 0.5 0.5 0.5\n",
      " 0.  1.  1.  0.5 1.  0.5 0.5 1.  0.5 1.  0.5 0.5 0.5 1.  0.5 0.5 1.  1.\n",
      " 0.5 1.  0.  1.  1.  1.  1.  0.  0.5 1.  1.  0.5 0.5 1.  1.  0.5 0.5 0.5\n",
      " 1.  1.  0.  1.  0.5 0.5 0.5 1.  1.  0.5 1.  1.  1.  1.  1.  1.  1.  1.\n",
      " 1.  1.  1.  1.  0.  1.  1.  1.  1.  1. ]\n",
      "Mean Accuracy: 0.785\n"
     ]
    }
   ],
   "source": [
    "# Definir características y variable objetivo\n",
    "X = titanic_data[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]\n",
    "y = titanic_data['Survived']\n",
    "\n",
    "# Definir los transformadores para características numéricas y categóricas\n",
    "numerical_features = ['Age', 'Fare']\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Crear el preprocesador para combinar los transformadores\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Crear un Pipeline con el preprocesador y el clasificador\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# Realizar la validación cruzada con 5 pliegues\n",
    "cv_results = cross_val_score(pipeline, X, y, cv=100, scoring='accuracy')\n",
    "\n",
    "# Mostrar los resultados de la validación cruzada\n",
    "print(f'Cross-Validation Accuracies: {cv_results}')\n",
    "print(f'Mean Accuracy: {np.mean(cv_results)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Piecewise Mechanism for Numeric Data\n",
    "def piecewise_mechanism(t_i_vector, epsilon):\n",
    "    t_i_tensor = torch.tensor(t_i_vector, dtype=torch.float32)\n",
    "    t_i_tensor = torch.clamp(t_i_tensor, -1, 1)\n",
    "    C = (torch.exp(torch.tensor(epsilon / 2)) + 1) / (torch.exp(torch.tensor(epsilon / 2)) - 1)\n",
    "    \n",
    "    def l(t_i):\n",
    "        return (C + 1) / 2 * t_i - (C - 1) / 2\n",
    "    \n",
    "    def r(t_i):\n",
    "        return l(t_i) + C - 1\n",
    "\n",
    "    x = torch.rand(t_i_tensor.shape)\n",
    "    threshold = torch.exp(torch.tensor(epsilon / 2)) / (torch.exp(torch.tensor(epsilon / 2)) + 1)\n",
    "    \n",
    "    t_i_star = torch.empty(t_i_tensor.shape, dtype=torch.float32)\n",
    "    \n",
    "    for i in range(t_i_tensor.shape[0]):\n",
    "        l_val = l(t_i_tensor[i])\n",
    "        r_val = r(t_i_tensor[i])\n",
    "        \n",
    "        if x[i] < threshold:\n",
    "            if l_val >= r_val:\n",
    "                r_val = l_val + 1e-5\n",
    "            t_i_star[i] = torch.distributions.Uniform(l_val, r_val).sample()\n",
    "        else:\n",
    "            if torch.rand(1) < 0.5:\n",
    "                if -C >= l_val:\n",
    "                    l_val = -C + 1e-5\n",
    "                t_i_star[i] = torch.distributions.Uniform(-C, l_val).sample()\n",
    "            else:\n",
    "                if r_val >= C:\n",
    "                    r_val = C - 1e-5\n",
    "                t_i_star[i] = torch.distributions.Uniform(r_val, C).sample()\n",
    "\n",
    "    return t_i_star.numpy()\n",
    "\n",
    "# PrivacyPreserving class for categorical data\n",
    "class PrivacyPreserving:\n",
    "    def __init__(self, df, column, epsilon, seed=None):\n",
    "        self.df = df.copy()\n",
    "        self.column = column\n",
    "        self.epsilon = epsilon\n",
    "        self.categories = df[column].unique()\n",
    "        self.category_to_index = {category: i for i, category in enumerate(self.categories)}\n",
    "        self.index_to_category = {i: category for i, category in enumerate(self.categories)}\n",
    "        self.d = len(self.categories)\n",
    "        self.seed = seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "    \n",
    "    def apply_privacy_method(self, method_name):\n",
    "        if method_name == \"direct_encoding_privacy\":\n",
    "            return self.direct_encoding_privacy()[self.column]\n",
    "        elif method_name == \"optimized_unary_encoding_privacy\":\n",
    "            return self.optimized_unary_encoding_privacy()[self.column]\n",
    "        elif method_name == \"rappor_privacy\":\n",
    "            return self.rappor_privacy()[self.column]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid privacy method name: {method_name}\")\n",
    "    \n",
    "    def direct_encoding_privacy(self):\n",
    "        def direct_encoding(value, d, epsilon):\n",
    "            p = np.exp(epsilon) / (np.exp(epsilon) + d - 1)\n",
    "            q = 1 / (np.exp(epsilon) + d - 1)\n",
    "            \n",
    "            probabilities = np.full(d, q)\n",
    "            probabilities[self.category_to_index[value]] = p\n",
    "            privatized_index = np.random.choice(d, p=probabilities)\n",
    "            return self.index_to_category[privatized_index]\n",
    "        \n",
    "        df_priv = self.df.copy()\n",
    "        df_priv[self.column] = df_priv[self.column].apply(lambda x: direct_encoding(x, self.d, self.epsilon))\n",
    "        return df_priv\n",
    "    \n",
    "    def optimized_unary_encoding_privacy(self):\n",
    "        def optimized_unary_encoding(value, d, epsilon):\n",
    "            p = 0.5\n",
    "            q = 1 / (np.exp(epsilon) + 1)\n",
    "            \n",
    "            binary_vector = np.zeros(d)\n",
    "            binary_vector[self.category_to_index[value]] = 1\n",
    "            \n",
    "            perturbed_vector = np.zeros(d)\n",
    "            for i in range(d):\n",
    "                if binary_vector[i] == 1:\n",
    "                    perturbed_vector[i] = np.random.choice([1, 0], p=[p, 1 - p])\n",
    "                else:\n",
    "                    perturbed_vector[i] = np.random.choice([1, 0], p=[q, 1 - q])\n",
    "            \n",
    "            indices_positivos = np.where(perturbed_vector == 1)[0]\n",
    "            if len(indices_positivos) == 0:\n",
    "                indices_positivos = [self.category_to_index[value]]\n",
    "            \n",
    "            privatized_index = np.random.choice(indices_positivos)\n",
    "            return self.index_to_category[privatized_index]\n",
    "        \n",
    "        df_priv = self.df.copy()\n",
    "        df_priv[self.column] = df_priv[self.column].apply(lambda x: optimized_unary_encoding(x, self.d, self.epsilon))\n",
    "        return df_priv\n",
    "    \n",
    "    def rappor_privacy(self):\n",
    "        def rappor_encode(value, d, f=0.5):\n",
    "            binary_vector = np.zeros(d)\n",
    "            binary_vector[self.category_to_index[value]] = 1\n",
    "            \n",
    "            perturbed_vector = np.zeros(d)\n",
    "            for i in range(d):\n",
    "                if binary_vector[i] == 1:\n",
    "                    perturbed_vector[i] = np.random.choice([1, 0], p=[1 - f, f])\n",
    "                else:\n",
    "                    perturbed_vector[i] = np.random.choice([1, 0], p=[f, 1 - f])\n",
    "            \n",
    "            indices_positivos = np.where(perturbed_vector == 1)[0]\n",
    "            if len(indices_positivos) == 0:\n",
    "                indices_positivos = [self.category_to_index[value]]\n",
    "            \n",
    "            privatized_index = np.random.choice(indices_positivos)\n",
    "            return self.index_to_category[privatized_index]\n",
    "        \n",
    "        df_priv = self.df.copy()\n",
    "        df_priv[self.column] = df_priv[self.column].apply(lambda x: rappor_encode(x, self.d))\n",
    "        return df_priv\n",
    "\n",
    "# Apply local differential privacy to numeric and categorical variables\n",
    "\n",
    "def apply_numerical_privacy(X, numerical_columns, epsilon):\n",
    "    for column in numerical_columns:\n",
    "        X[column] = piecewise_mechanism(X[[column]].values, epsilon)\n",
    "    return X\n",
    "\n",
    "def apply_categorical_privacy(X, categorical_columns, epsilon, method_name):\n",
    "    for column in categorical_columns:\n",
    "        privacy_preserver = PrivacyPreserving(X, column, epsilon)\n",
    "        X[column] = privacy_preserver.apply_privacy_method(method_name)\n",
    "    return X\n",
    "# Prepare dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 60 members, which is less than n_splits=100.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracies: [0.5 1.  0.5 1.  0.5 1.  1.  0.5 0.5 1.  1.  1.  0.5 0.5 1.  1.  1.  1.\n",
      " 1.  1.  1.  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 1.  0.  0.5 1.  1.\n",
      " 0.5 0.5 0.5 1.  0.5 0.5 0.  1.  0.5 1.  1.  0.  0.5 0.5 0.  0.5 1.  0.5\n",
      " 1.  1.  0.  1.  0.5 0.5 0.5 0.5 0.5 0.  0.5 0.5 1.  0.5 0.5 1.  1.  0.\n",
      " 0.  1.  0.5 0.5 1.  0.5 0.5 0.  0.5 0.5 1.  1.  1.  1.  1.  0.  1.  1.\n",
      " 1.  1.  1.  1.  1.  0.  1.  1.  0.  1. ]\n",
      "Mean Accuracy: 0.665\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming the privacy methods and Normalizer class are already defined\n",
    "\n",
    "# Apply privacy-preserving transformations\n",
    "epsilon = 1 # Privacy budget\n",
    "\n",
    "# Drop rows with missing values to simplify the process\n",
    "titanic_data = titanic_data.dropna()\n",
    "\n",
    "# Define features and target\n",
    "X = titanic_data[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]\n",
    "y = titanic_data['Survived']\n",
    "\n",
    "# Step 1: Apply privacy-preserving transformations to numerical columns\n",
    "numerical_columns = ['Age', 'Fare']\n",
    "X_priv_numerical = apply_numerical_privacy(X.copy(), numerical_columns, epsilon)\n",
    "\n",
    "# Step 2: Apply privacy-preserving transformations to categorical columns\n",
    "categorical_columns = ['Pclass', 'Sex', 'Embarked']\n",
    "X_priv_categorical = apply_categorical_privacy(X.copy(), categorical_columns, epsilon, 'rappor_privacy')\n",
    "\n",
    "# Combine numerical and categorical transformations\n",
    "X_priv_combined = X_priv_numerical.copy()\n",
    "X_priv_combined[categorical_columns] = X_priv_categorical[categorical_columns]\n",
    "\n",
    "# Step 3: Apply differential privacy to the target variable (y, 'Survived')\n",
    "y_priv_df = pd.DataFrame({'Survived': y})\n",
    "y_priv = PrivacyPreserving(y_priv_df, 'Survived', epsilon).apply_privacy_method('rappor_privacy')\n",
    "y_priv = y_priv_df['Survived']  # Extract the transformed 'Survived' column after privacy\n",
    "\n",
    "# Step 4: Define the column transformer for imputing missing values and encoding categorical features\n",
    "numerical_features = ['Age', 'Fare']\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Define the preprocessor for the pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Step 5: Create a Pipeline with the preprocessor and the classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# Step 6: Apply cross-validation to evaluate the model\n",
    "# Use cross-validation to calculate accuracy across multiple folds\n",
    "cv_results = cross_val_score(pipeline, X_priv_combined, y_priv, cv=100, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'Cross-Validation Accuracies: {cv_results}')\n",
    "print(f'Mean Accuracy: {np.mean(cv_results)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
